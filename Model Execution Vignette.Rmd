---
title: Model Execution Vignette
subtitle: Working with the Prime File
author: "Henning Winker, Felipe Carvalho, Maia Kapur"
geometry: margin = 1in
output:
  html_document
fontsize: 11pt
---
The code below can be used to reproduce analysis and figures from Winker et al (2018, in review), when used in conjuntion with `JABBAv4R1.r` and data from the South Atlantic Swordfish Fishery.

Surplus Production Models (SPMs) are among the least parameter and data
demanding population models that can produce estimates of the Maximum
Sustainable Yield (MSY) and associated fisheries reference points. Despite a number of limitations (Maunder refs), SPMs remain an integral tool for data-limited to -moderate stock assessments (REFs
), Management Evaluation Strategies and meta-analyses of global fisheries (Refs). Also known as Biomass Dynamics Models (Hilborn and Walters 1992), SPMs predominantly persist as routine assessment tool for chondrichthyes (McAllister et al. 2001, Carvalho et al. 2014), invertebrates (Zhou et al. 2009, 2011, Ono et al. 2012) and to a notable extend within their traditional realm of large pelagic tuna and billfish assessments (Brodziak and Ishimura 2012, Chang et al. 2014, Punt et al. 2015).

Sustainable Yield (MSY) and associated fisheries reference points. Despite a number of limitations (Maunder refs), SPMs remain an integral tool for data-limited to -moderate stock assessments (REFs), Management Evaluation Strategies and meta-analyses of global fisheries (Refs). Also known as Biomass Dynamics Models (Hilborn and Walters 1992), SPMs predominantly persist as routine assessment tool for chondrichthyes (McAllister et al. 2001, Carvalho et al. 2014), invertebrates (Zhou et al. 2009, 2011, Ono et al. 2012) and to a notable extend within their traditional realm of large pelagic tuna and billfish assessments (Brodziak and Ishimura 2012, Chang et al. 2014, Punt et al. 2015).


# Part I - End-user model execution
The end-user will specify and execute the simulation using the following commands. The user will necessarliy `source()` the full `JABBA` model, which is detailed in Part II.

The user specifies which of four model types to implement, amongst:

+  1. Schaefer
+  2. Schaefer with Depensation (CMSY: Froese et al. 2016)
+  3. Pella-Tomlinson
+  4. Fox
+  5. Fox with Depensation (CMSY: Froese et al. 2016)


## Assignment of model priors
Because prior formulations for most SPM-based assessments are specified for r, we provide the following equation to easily convert r estimates (or prior means) into HMSY for any given shape parameter input m:

$$H_{MSY} = r\frac{m-1}{1-m^{-1}}$$

However, if the prior for r is derived based on Leslie matrix approach, as commonly used for a logistic Schaefer model, we recommend approximating HMSY  = r / 2 for the purpose of comparability among Schaefer, Fox and Pella-Tomlinson production function. 

Equations (5) - (10) in the reference paper illustrate the direct link between the Pella-Tomlinson SPM and the age-structured, which emphasizes the potential for deriving informative priors for r and m from spawning biomass- and yield-per-recruit analysis with integrated spawning recruitment relationships by generating deviates of $H_{MSY} = MSY/B_{MSY}$ and $B_{MSY}/K$, respectively (Maunder 2003, Thorson et al. 2012b, Wang et al. 2014).


```{r Run Simulation, eval = F, warning = F, message = F}
##><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><><><
## JABBA: Just Another Bayesian Biomass Assessment
## Input File for JABBA
## Developed by Henning Winker & Felipe Carvalho (Cape Town/Hawaii)  
##><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>

# required packages
library(gplots)
library(coda)
library(rjags)
library(R2jags)
library("fitdistrplus")
library(reshape)

#----------------------------------------------------------------
# Setup working directories and output folder labels 
#-----------------------------------------------------------------
# Set Working directory file, where assessments are stored 
File = "C:/Users/Maia.Kapur/Downloads/MS_JABBA_R1codes"
# Set working directory for JABBA R source code
JABBA.file = "C:/Users/Maia.Kapur/Downloads/MS_JABBA_R1codes"
# Set Assessment file: assement folder within File that includes .csv input files
assessment = "SWO_SA" 
# add specifier for assessment (File names of outputs)

#----------------------------------------------------------------


#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
# Graphic, Output, Saving (.RData) settings 
#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
KOBE.plot = TRUE # Produces JABBA Kobe plot 
KOBE.type = c("ICCAT","IOTC")[2] # ICCAT uses 3 colors; IOTC 4 (incl. orange) 
Biplot= TRUE # Produces a "post-modern" biplot with buffer and target zones (Quinn & Collie 2005)
SP.plot = c("standard","phase")[2] # Produces standard or 'Kobe phase' SP plot  
save.trajectories =TRUE # saves posteriors of P=B/K, B/Bmsy and H/Hmsy as .RData object 
harvest.label = c("Hmsy","Fmsy")[2] # choose label preference H/Hmsy versus Fmsy
CPUE.plot= TRUE # Runs state-tool to produce "alligned" multi-CPUE plot  
meanCPUE = FALSE # Uses averaged CPUE from state-space tool instead of individual indices  
Projection = TRUE # Use Projections: requires to define TACs vectors 
save.projections = TRUE # saves projection posteriors as .RData object 
# Save entire posterior as .RData object
save.all = FALSE # (if TRUE, a very large R object of entire posterior is saved)  
#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>


#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
# Optional: Note Scenarios
#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
# S1: Model including Brazil1 
# S2: Model excluding Brazil1
# S3: Base-case Model with time blocks on ESP and JPN 
#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
# Specify Scenario name for output file names
Scenarios = c(paste0("Scenario",1:3)) 

# Execute multiple JABBA runs in loop 
for(s in 3:3){
Scenario = Scenarios[s] 

# Choose model type: 
# 1: Schaefer
# 2: Fox  
# 3: Pella-Tomlinsson  


Model = c(3,3,3,3,3)[s] 
Mod.names = c("Schaefer","Fox","Pella")[Model]

#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
# Set Plim = Blim/K where recruitment may become impaired (e.g. Plim = 0.25) (depensation opiton) 
# Choose Plim = 0 to reduce to conventional Schaefer, Fox, Pella model 
Plim = 0
#><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>

  
  # Settings for Pella-Tomlinson
  if(Model==3){
  
  BmsyK = 0.4 # Set Surplus Production curve inflection point
  
  #-----------------------------------------------
  # find inflection point
  ishape = NULL
  # Find shape for  SBmsytoK 
  ishape = seq(0.1,10,0.001)
  
  check.shape =((ishape)^(-1/(ishape-1))-BmsyK)^2
  
  #  Set shape (> 0, with 1.001 ~ Fox and 2 = Schaefer)
  shape =  ishape[check.shape==min(check.shape)] 
  } else {shape=FALSE}
  #------------------------------------------------

  # Use SEs for abudance indices (TRUE/FALSE)
  SE.I = TRUE
  
  # Load assessment data
  catch = read.csv(paste0(File,"/",assessment,"/catch",assessment,".csv"))
  cpue = read.csv(paste0(File,"/",assessment,"/cpue",assessment,".csv"))#
  
  if(SE.I ==TRUE){
  se =  read.csv(paste0(File,"/",assessment,"/se",assessment,".csv"))
  }
  
  names(cpue)
  names(catch)
  
  #--------------------------------------------------
  # option to exclude CPUE time series or catch year
  #--------------------------------------------------
  
  # Set up Base-Case for SWO
  
  #if(s<4 | s>4){
    cpue = cpue[,-c(10:12)]
   se = se[,-c(10:12)]
  #}
  
  if(s<3){ # Combine SPA and JAPAN
    cpue[,4] = apply(cpue[,4:5],1,mean,na.rm=TRUE)
    cpue[,6] = apply(cpue[,6:7],1,mean,na.rm=TRUE)
    
    cpue = cpue[,-c(5,7)] 
    se[,4] = apply(se[,4:5],1,mean,na.rm=TRUE)
    se[,6] = apply(se[,6:7],1,mean,na.rm=TRUE)
    
    se = se[,-c(5,7)]
    cpue[!is.finite(cpue[,4]),4]=NA
    cpue[!is.finite(cpue[,5]),5]=NA
    se[!is.finite(se[,4]),4]=NA
    se[!is.finite(se[,5]),5]=NA
    
  }
  
  # Remove BrazilI
  if(s>1){
    cpue = cpue[,-c(2)]
    se = se[,-c(2)]
  }
  
  
  names(cpue)
  ncol(catch)
  ncol(cpue)
   
  #------------------------------------------------------
  # Option use mean CPUE from state-space cpue averaging
  #-----------------------------------------------------
  #meanCPUE = TRUE
  
  #------------------------------------------------
  # Prior for unfished biomass K
  #------------------------------------------------
  # The option are: 
  # a) Specify as a lognormal prior with mean and CV 
  # b) Specify as range to be converted into lognormal prior
  
  K.dist = c("lnorm","range")[1]
  
  # if lnorm use mean and CV; if range use lower,upper bound
  K.prior = c(200000,1) 
  
  #-----------------------------------------------------------
  # mean and CV and sd for Initial depletion level P1= SB/SB0
  #-----------------------------------------------------------
  # Set the initial depletion prior B1/K 
  # To be converted into a lognormal prior (with upper bound at 1.1)
  
  psi.dist= c("lnorm","beta")[1]
  # specify as mean and CV 
  psi.prior = c(1,0.25) 
  
  #--------------------------------------------------------------
  # Determine estimation for catchability q and observation error 
  #--------------------------------------------------------------
  # Assign q to CPUE
  sets.q = 1:(ncol(cpue)-1) 
  
  
  #----------------------------------------------------
  # Determine r prior
  #----------------------------------------------------
  # The option are: 
  # a) Specifying a lognormal prior 
  # b) Specifying a resiliance category after Froese et al. (2016; CMSY)
  # Resilience: "Very low", "Low", "Medium", High" (requires r.range = TRUE)
  
  # use range or mean/stdev
  r.dist = c("lnorm","range")[1] # Set to 1 for mean/stdev specifications
  
  r.prior = c(0.42,0.37) # as range with upper and lower bound of lnorm prior
  
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>>
  # Observation Error
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>>
  
  #To Estimate additional observation variance set sigma.add = TRUE
  sigma.est = TRUE

  # Series
  sets.var = 1:(ncol(cpue)-1) # estimate individual additional variace
  
  # As option for data-weighing
  # minimum fixed observation error for each variance set (optional choose 1 value for both)
  fixed.obsE = c(0.2) # Important if SE.I is not availble
  
  # Total observation error: TOE = sqrt(SE^2+sigma.est^2+fixed.obsE^2)
  
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>>
  # Process Error
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>>
  #Estimate set sigma.proc == True
  sigma.proc = TRUE
  # Determines if process error deviation are estimated for all years (TRUE)  
  # or only from the point the first abundance index becomes available (FALSE)
  proc.dev.all = FALSE 
  #------------------------------------------
  if(sigma.proc == TRUE){
  igamma = c(4,0.01) #specify inv-gamma parameters
  
  # Process error check
  gamma.check = 1/rgamma(1000,igamma[1],igamma[2])
  # check mean process error + CV
  mu.proc = sqrt(mean(gamma.check)); CV.proc = sd(sqrt(gamma.check))/mean(sqrt(gamma.check))
  
  # check CV
  round(c(mu.proc,CV.proc),3)
  quantile(sqrt(gamma.check),c(0.1,0.9))
  }else{
  sigma.proc = 0.07 #IF Fixed: typicallly 0.05-0.15 (see Ono et al. 2012)
  }
  #--------------------------------------------
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>>
  # Optional: Do TAC Projections
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>>
  Projection = TRUE # Switch on by Projection = TRUE 
  
  # Check final year catch 
  catch[nrow(catch),]
  
  # Set range for alternative TAC projections
  TACs = seq(10000,18000,1000) #example
  
  # Intermitted TAC to get to current year
  #TACint = mean(catch[nrow(catch)-3,2]:catch[nrow(catch),2]) # avg last 3 years
  TACint = 10058 # Catch for 2016
  # Set number of projections years
  pyrs = 10
  
  
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
  # Execute model and produce output
  #><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>><>
  
  # MCMC settings
  ni <- 30000 # Number of iterations
  nt <- 5 # Steps saved
  nb <- 5000 # Burn-in
  nc <- 2 # number of chains
  nsaved = (ni-nb)/nt*nc
  
   # Run model (BSPSPexe file must be in the same working directory)
  source(paste0(JABBA.file,"/JABBAv4R1.r")) 
 
  }# THE END
```
 